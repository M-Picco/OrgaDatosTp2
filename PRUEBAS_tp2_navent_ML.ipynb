{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de postulación para un aviso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import gc\n",
    "import datetime\n",
    "import re\n",
    "from math import sqrt\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 1500000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y limpieza de datos / Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postulantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargo postulantes\n",
    "df_postulantes1 = pd.read_csv('../datos_navent_fiuba/datos_navent/fiuba_2_postulantes_genero_y_edad.csv', parse_dates=['fechanacimiento'])\n",
    "df_postulantes2 = pd.read_csv('../datos_navent_fiuba/fiuba_hasta_15_abril/fiuba_2_postulantes_genero_y_edad.csv', parse_dates=['fechanacimiento'])\n",
    "df_postulantes3 = pd.read_csv('../datos_navent_fiuba/fiuba_desde_15_abril/fiuba_2_postulantes_genero_y_edad.csv', parse_dates=['fechanacimiento'])\n",
    "\n",
    "df_postulantes = df_postulantes1.append(df_postulantes2).append(df_postulantes3)\n",
    "\n",
    "del df_postulantes1\n",
    "del df_postulantes2\n",
    "del df_postulantes3\n",
    "\n",
    "df_postulantes.drop_duplicates(['idpostulante'], keep='first', inplace=True)\n",
    "\n",
    "df_postulantes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "# guardamos los codificadores (label => numero y visceversa) en un diccionario\n",
    "label_encoders = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limpieza de datos de fecha de nacimiento\n",
    "df_postulantes['fechanacimiento'] = pd.to_datetime(df_postulantes['fechanacimiento'], errors='coerce')\n",
    "\n",
    "df_postulantes['edad'] = datetime.datetime.now().year - df_postulantes['fechanacimiento'].dt.year\n",
    "df_postulantes['edad'] = df_postulantes['edad'].fillna(0)\n",
    "\n",
    "df_postulantes = df_postulantes.drop(['fechanacimiento'], axis=1)\n",
    "\n",
    "df_postulantes = df_postulantes.loc[(df_postulantes['sexo'] == 'FEM') | (df_postulantes['sexo'] == 'MASC') | (df_postulantes['sexo'] == 'NO_DECLARA')]\n",
    "\n",
    "# convierto variables categóricas a numéricas\n",
    "label_encoders['sexo'] = LabelEncoder().fit(['FEM', 'MASC', 'NO_DECLARA'])\n",
    "df_postulantes['sexo'] = label_encoders['sexo'].transform(df_postulantes['sexo'])\n",
    "\n",
    "print(df_postulantes.shape)\n",
    "print(df_postulantes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Educacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargo educacion de los estudiantes\n",
    "df_edu1 = pd.read_csv('../datos_navent_fiuba/datos_navent/fiuba_1_postulantes_educacion.csv')\n",
    "df_edu2 = pd.read_csv('../datos_navent_fiuba/fiuba_hasta_15_abril/fiuba_1_postulantes_educacion.csv')\n",
    "df_edu3 = pd.read_csv('../datos_navent_fiuba/fiuba_desde_15_abril/fiuba_1_postulantes_educacion.csv')\n",
    "\n",
    "df_edu = df_edu1.append(df_edu2).append(df_edu3)\n",
    "\n",
    "del df_edu1\n",
    "del df_edu2\n",
    "del df_edu3\n",
    "gc.collect()\n",
    "\n",
    "print(df_edu.shape)\n",
    "print(df_edu.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renombro columnas para no confundirlas luego de mergear\n",
    "df_edu = df_edu.rename(columns={'nombre':'nombre_edu', 'estado': 'estado_edu'});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convierto variables categóricas a numéricas\n",
    "label_encoders['nombre_edu'] = LabelEncoder().fit(df_edu['nombre_edu'])\n",
    "label_encoders['estado_edu'] = LabelEncoder().fit(df_edu['estado_edu'])\n",
    "\n",
    "df_edu['nombre_edu'] = label_encoders['nombre_edu'].transform(df_edu['nombre_edu'])\n",
    "df_edu['estado_edu'] = label_encoders['estado_edu'].transform(df_edu['estado_edu'])\n",
    "\n",
    "df_edu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts_edu = df_postulantes.merge(df_edu, on='idpostulante', how='left')\n",
    "\n",
    "df_posts_edu['nombre_edu'] = df_posts_edu['nombre_edu'].fillna(-1)\n",
    "df_posts_edu['estado_edu'] = df_posts_edu['estado_edu'].fillna(-1)\n",
    "\n",
    "# me quedo con el de mayor educacion registro para cada postulante\n",
    "df_posts_edu.sort_values(by='nombre_edu', ascending=False)\n",
    "\n",
    "df_posts_edu.drop_duplicates(subset = \"idpostulante\",keep= \"first\", inplace=True)\n",
    "\n",
    "print(df_posts_edu.shape)\n",
    "print(df_posts_edu.head())\n",
    "\n",
    "del df_edu\n",
    "del df_postulantes\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postulaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargo postulaciones\n",
    "df_postulaciones1 = pd.read_csv('../datos_navent_fiuba/datos_navent/fiuba_4_postulaciones.csv', parse_dates=['fechapostulacion'])\n",
    "df_postulaciones2 = pd.read_csv('../datos_navent_fiuba/fiuba_hasta_15_abril/fiuba_4_postulaciones.csv', parse_dates=['fechapostulacion'])\n",
    "\n",
    "df_postulaciones = df_postulaciones1.append(df_postulaciones2)\n",
    "\n",
    "del df_postulaciones1\n",
    "del df_postulaciones2\n",
    "gc.collect()\n",
    "\n",
    "df_postulaciones.drop_duplicates(['idaviso', 'idpostulante'], keep='first', inplace=True)\n",
    "\n",
    "print(df_postulaciones.shape)\n",
    "print(df_postulaciones.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postulaciones.drop('fechapostulacion', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avisos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargo avisos\n",
    "df_avisos1 = pd.read_csv('../datos_navent_fiuba/datos_navent/fiuba_6_avisos_detalle.csv')\n",
    "df_avisos2 = pd.read_csv('../datos_navent_fiuba/fiuba_hasta_15_abril/fiuba_6_avisos_detalle.csv')\n",
    "df_avisos3 = pd.read_csv('../datos_navent_fiuba/fiuba_desde_15_abril/fiuba_6_avisos_detalle.csv')\n",
    "df_avisos4 = pd.read_csv('../datos_navent_fiuba/fiuba_desde_15_abril/fiuba_6_avisos_detalle_missing_nivel_laboral.csv')\n",
    "\n",
    "df_avisos = df_avisos1.append(df_avisos2).append(df_avisos3).append(df_avisos4)\n",
    "\n",
    "del df_avisos1\n",
    "del df_avisos2\n",
    "del df_avisos3\n",
    "del df_avisos4\n",
    "gc.collect()\n",
    "\n",
    "df_avisos = df_avisos.drop_duplicates(['idaviso'], keep='first')\n",
    "\n",
    "print(df_avisos.shape)\n",
    "print(df_avisos.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avisos online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargo avisos\n",
    "df_avisos_online1 = pd.read_csv('../datos_navent_fiuba/datos_navent/fiuba_5_avisos_online.csv')\n",
    "df_avisos_online2 = pd.read_csv('../datos_navent_fiuba/fiuba_hasta_15_abril/fiuba_5_avisos_online.csv')\n",
    "\n",
    "df_avisos_online = df_avisos_online1.append(df_avisos_online2)\n",
    "\n",
    "del df_avisos_online1\n",
    "del df_avisos_online2\n",
    "gc.collect()\n",
    "\n",
    "df_avisos_online = df_avisos_online.drop_duplicates(['idaviso'], keep='first')\n",
    "df_avisos_online['online'] = 1\n",
    "\n",
    "print(df_avisos_online.shape)\n",
    "print(df_avisos_online.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avisos = df_avisos.merge(df_avisos_online, how='left', on='idaviso')\n",
    "\n",
    "del df_avisos_online\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avisos = df_avisos.drop(['mapacalle'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limpieza de NaN, nan, None, etc.\n",
    "df_avisos['ciudad'] = df_avisos['ciudad'].fillna('None')\n",
    "df_avisos['titulo'] = df_avisos['titulo'].fillna('None')\n",
    "df_avisos['descripcion'] = df_avisos['descripcion'].fillna('None')\n",
    "df_avisos['denominacion_empresa'] = df_avisos['denominacion_empresa'].fillna('None')\n",
    "df_avisos['nivel_laboral'] = df_avisos['nivel_laboral'].fillna('None')\n",
    "\n",
    "df_avisos['online'] = df_avisos['online'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convierto variables categóricas a numéricas\n",
    "label_encoders['nombre_zona'] = LabelEncoder().fit(df_avisos['nombre_zona'])\n",
    "label_encoders['ciudad'] = LabelEncoder().fit(df_avisos['ciudad'])\n",
    "label_encoders['tipo_de_trabajo'] = LabelEncoder().fit(df_avisos['tipo_de_trabajo'])\n",
    "label_encoders['nivel_laboral'] = LabelEncoder().fit(df_avisos['nivel_laboral'])\n",
    "label_encoders['nombre_area'] = LabelEncoder().fit(df_avisos['nombre_area'])\n",
    "label_encoders['denominacion_empresa'] = LabelEncoder().fit(df_avisos['denominacion_empresa'])\n",
    "\n",
    "df_avisos['nombre_zona'] = label_encoders['nombre_zona'].transform(df_avisos['nombre_zona'])\n",
    "df_avisos['ciudad'] = label_encoders['ciudad'].transform(df_avisos['ciudad'])\n",
    "df_avisos['tipo_de_trabajo'] = label_encoders['tipo_de_trabajo'].transform(df_avisos['tipo_de_trabajo'])\n",
    "df_avisos['nivel_laboral'] = label_encoders['nivel_laboral'].transform(df_avisos['nivel_laboral'])\n",
    "df_avisos['nombre_area'] = label_encoders['nombre_area'].transform(df_avisos['nombre_area'])\n",
    "df_avisos['denominacion_empresa'] = label_encoders['denominacion_empresa'].transform(df_avisos['denominacion_empresa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avisos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trabajando el texto/titulo de los avisos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_limpiar_html_tags = re.compile('<.*?>')\n",
    "def limpiar_html(strhtml):\n",
    "    return re.sub(regex_limpiar_html_tags, '', strhtml)\n",
    "\n",
    "def regularizar_texto(linea):\n",
    "    return limpiar_html(linea)\\\n",
    "                        .lower()\\\n",
    "                        .replace('á', 'a')\\\n",
    "                        .replace('é', 'e')\\\n",
    "                        .replace('í', 'i')\\\n",
    "                        .replace('ó', 'o')\\\n",
    "                        .replace('ú', 'u')\\\n",
    "                        .replace('\\t', '')\\\n",
    "                        .replace('\\n', '')\\\n",
    "                        .replace('\\r', '')\n",
    "                        \n",
    "vregularizar_texto = np.vectorize(regularizar_texto)\n",
    "\n",
    "columnas_terminos = {\n",
    "#    'ingenieria': ['ingeniero', 'ingeniera', 'ingenieria'],\n",
    "#    'software': ['javascript', 'java', 'html', 'css', 'c#', '.net', 'android', 'ios', 'php', 'c++', 'sql', 'it resources'],\n",
    "#    'lunes_a_viernes': ['lunes a viernes', 'lun a vier', 'lun a vie'],\n",
    "#    'requiere_titulo': ['titulo secundario', 'titulo terciario', 'titulo universitario', 'secundario completo', 'estudios completo', 'universitarios completo'],\n",
    "#    'marketing': ['marketing', 'telemarketer', 'telemarketing', 'marketer', 'media manager', 'callcenter', 'call center'],\n",
    "#    'capacitacion': ['capacitacion'],\n",
    "#    'idioma_ingles': ['idioma ingles', 'manejo de ingles', 'clases de ingles', 'ingles excluyente', 'ingles requerido'],\n",
    "#    'multinacional': ['multinacional'],\n",
    "#    'internacional': ['internacional'],\n",
    "#    'atencion_al_cliente': ['atencion al cliente', 'call center', 'callcenter', 'soporte tecnico', 'area de soporte', 'tareas de soporte'],\n",
    "#    'turismo': ['turismo'],\n",
    "#    'zona_puerto_madero': ['puerto madero'],\n",
    "#    'zona_centro': ['microcentro', 'tribunales'],\n",
    "#    'experiencia_previa': ['experiencia previa', 'experiencias anteriores', 'años de experiencia'],\n",
    "#    'obra_social': ['obra social', 'osde', 'swiss medical', 'galeno', 'wh hope', 'grupo familiar', 'cobertura medica', 'pre paga', 'prepaga'],\n",
    "#    'puesto_gerencia': ['gerente', 'gerenta', 'gerencia'],\n",
    "#    'requisitos_excluyentes': ['excluyente'],\n",
    "#    'retail': ['hipermercado', 'supermercado', 'cadena', 'franquicia', 'fravega', 'retail', 'vendedor'],\n",
    "#    'chofer': ['chofer', 'taxi', 'remis', 'colectivo', 'reparto', 'furgon', 'camion'],\n",
    "#    'medicina': ['medic', 'hospital', 'clinica', 'farmacia']\n",
    "}\n",
    "\n",
    "def tiene_termino(texto1, texto2, terminos):\n",
    "    for t in terminos:\n",
    "        if t in texto1 or t in texto2:\n",
    "            return 1\n",
    "    return 0\n",
    "def vtiene_termino(serie1, serie2, terminos):\n",
    "    if len(serie1) != len(serie2):\n",
    "        raise ValueError('series de distinto largo')\n",
    "    s = []\n",
    "    for i in range(0, len(serie1)):\n",
    "        s.append(tiene_termino(serie1.iloc[i], serie2.iloc[i], terminos))\n",
    "    return pd.Series(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avisos['titulo'] = vregularizar_texto(df_avisos['titulo'])\n",
    "df_avisos['descripcion'] = vregularizar_texto(df_avisos['descripcion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizable, podríamos aplicar para cada fila todas las columnas del diccionario\n",
    "# como está ahora hace k*n con k=|columnas_terminos| y n=|df_avisos|\n",
    "for col, terminos in columnas_terminos.items():\n",
    "    df_avisos[col] = vtiene_termino(df_avisos['titulo'], df_avisos['descripcion'], terminos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columnas_terminos:\n",
    "    print(\"col = %s\" % col)\n",
    "    print(df_avisos[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avisos.drop(['titulo', 'descripcion'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargo tf idf \n",
    "df_avisos_tfidf = pd.read_csv(\"./kevin/df_aviso_svd.csv\")\n",
    "df_avisos= df_avisos.merge(df_avisos_tfidf, on= \"idaviso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "n = int(sqrt(df_avisos.shape[0]))\n",
    "kmeans = KMeans(n_clusters=n)\n",
    "kmeans.fit(df_avisos_tfidf)\n",
    "df_avisos['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avisos['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del kmeans\n",
    "del df_avisos_tfidf\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargo avisos\n",
    "df_vistas1 = pd.read_csv('../datos_navent_fiuba/datos_navent/fiuba_3_vistas.csv', parse_dates=['timestamp'])\n",
    "df_vistas2 = pd.read_csv('../datos_navent_fiuba/fiuba_hasta_15_abril/fiuba_3_vistas.csv', parse_dates=['timestamp'])\n",
    "df_vistas3 = pd.read_csv('../datos_navent_fiuba/fiuba_desde_15_abril/fiuba_3_vistas.csv', parse_dates=['timestamp'])\n",
    "\n",
    "df_vistas = df_vistas1.append(df_vistas2).append(df_vistas3)\n",
    "\n",
    "del df_vistas1\n",
    "del df_vistas2\n",
    "del df_vistas3\n",
    "gc.collect()\n",
    "\n",
    "df_vistas = df_vistas.rename(columns={'idAviso':'idaviso'})\n",
    "df_vistas = df_vistas.drop_duplicates(['idpostulante', 'idaviso'], keep='first')\n",
    "gc.collect()\n",
    "\n",
    "print(df_vistas.shape)\n",
    "print(df_vistas.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vistas['visto'] = 1\n",
    "df_vistas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vinculamos postulantes y avisos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postulaciones_merge = df_postulaciones.sample(SAMPLE_SIZE)\n",
    "\n",
    "# merge de todos los datos\n",
    "df_general = df_posts_edu.merge(df_postulaciones_merge, on='idpostulante').merge(df_avisos, on='idaviso')\n",
    "\n",
    "del df_postulaciones_merge\n",
    "gc.collect()\n",
    "\n",
    "print(df_general.shape)\n",
    "print(df_general.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de datos para entrenamiento y predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generación de postulaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_general['sepostulo'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generación de \"no\" postulaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = SAMPLE_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postulantes_sample = df_posts_edu.sample(sample, replace=True).reset_index().drop(\"index\",1)\n",
    "df_avisos_sample = df_avisos.sample(sample, replace=True).reset_index().drop(\"index\",1)\n",
    "\n",
    "print(df_postulantes_sample.shape)\n",
    "print(df_avisos_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_postulaciones = df_postulantes_sample.join(df_avisos_sample)\n",
    "\n",
    "del df_postulantes_sample\n",
    "del df_avisos_sample\n",
    "gc.collect()\n",
    "\n",
    "df_no_postulaciones = df_no_postulaciones.merge(df_postulaciones, on=[\"idaviso\",\"idpostulante\"], how=\"left\")\n",
    "df_no_postulaciones.drop_duplicates(['idaviso', 'idpostulante'], keep='first', inplace=True)\n",
    "print(df_no_postulaciones.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_postulaciones\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_postulaciones['sepostulo'] = 0;\n",
    "df_no_postulaciones.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_general.shape)\n",
    "df_general = df_general.append(df_no_postulaciones)\n",
    "print(df_general.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_no_postulaciones\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_general = df_general.merge(df_vistas, on=['idaviso', 'idpostulante'], how='left')\n",
    "df_general['visto'] = df_general['visto'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comentar si se quiere probar contra los dats de la competencia\n",
    "del df_posts_edu\n",
    "del df_avisos\n",
    "del df_vistas\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comentar si se quiere probar contra los dats de la competencia\n",
    "df_general = shuffle(df_general, random_state=13).reset_index()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comentar si se quiere probar contra los dats de la competencia\n",
    "offset = int(df_general.shape[0] * 0.8)\n",
    "\n",
    "df_general_entrenamiento = df_general.loc[:offset]\n",
    "df_general_test = df_general.loc[offset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comentar si se quiere probar contra los dats de la competencia\n",
    "del df_general\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecución del algoritmo de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_datos = ['sexo', 'edad', 'nombre_edu', 'estado_edu', 'idpais', 'nombre_zona', 'ciudad', 'tipo_de_trabajo', 'nivel_laboral', 'nombre_area', 'denominacion_empresa', 'online', 'visto', '0', '1', '2', '3', '4', '5', 'cluster'] + list(columnas_terminos.keys())\n",
    "columnas_target = ['sepostulo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_res(df_res, predicciones, algoritmo, clasificador):\n",
    "    now = datetime.datetime.now()\n",
    "    filename = \"./test_submissions/{0}-{1}-{2}.csv\".format(algoritmo, now.date(), now.time())\n",
    "    \n",
    "    df_res['sepostulo'] = predicciones\n",
    "    df_res.to_csv(filename, index=False)\n",
    "    \n",
    "    filename = \"./test_models/{0}-{1}-{2}.pkl\".format(algoritmo, now.date(), now.time())\n",
    "    joblib.dump(clasificador, filename)\n",
    "    \n",
    "def plot_importances(classifier):\n",
    "    imps = classifier.feature_importances_\n",
    "    indices = np.argsort(imps)[::-1][:10] # invierto el orden y tomo 10\n",
    "\n",
    "    x_labels = []\n",
    "    y_vals = []\n",
    "    for i in indices:\n",
    "        x_labels.append(columnas_datos[i])\n",
    "        y_vals.append(imps[i])\n",
    "\n",
    "    numeric_x_labels = range(0, len(y_vals))\n",
    "    plt.bar(numeric_x_labels, y_vals)\n",
    "    plt.xticks(numeric_x_labels, x_labels, rotation=75);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "params = {'n_estimators': 100, 'learning_rate': 0.001 }#, 'max_depth': a, 'min_samples_split': 2, }\n",
    "\n",
    "xgboostclassifier = GradientBoostingClassifier(**params)\n",
    "xgboostclassifier.fit(df_general_entrenamiento[columnas_datos], df_general_entrenamiento[columnas_target].values.ravel())\n",
    "\n",
    "sepostulo_predicciones_xgb = xgboostclassifier.predict(df_general_test[columnas_datos])\n",
    "\n",
    "plot_importances(xgboostclassifier)\n",
    "\n",
    "prec = precision_score(df_general_test[columnas_target], sepostulo_predicciones_xgb)\n",
    "print(\"Precision %.4f\" % (prec * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del xgboostclassifier\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descartamos la columan 'cluster' porque no da buenos resultados para RF\n",
    "columnas_datos = ['sexo', 'edad', 'nombre_edu', 'estado_edu', 'idpais', 'nombre_zona', 'ciudad', 'tipo_de_trabajo', 'nivel_laboral', 'nombre_area', 'denominacion_empresa', 'online', 'visto', '0', '1', '2', '3', '4', '5'] + list(columnas_terminos.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params = { 'n_estimators':300,'max_depth':17, 'random_state': 45, \"max_features\" : 0.320417} #0.320417 #0.125 creo que era\n",
    "params = { 'n_estimators': 30, 'max_depth': 17, 'random_state': 45, \"max_features\": 0.320417 }\n",
    "\n",
    "rndforestclassifier = RandomForestClassifier(**params)\n",
    "rndforestclassifier.fit(df_general_entrenamiento[columnas_datos], df_general_entrenamiento[columnas_target].values.ravel())\n",
    "sepostulo_predicciones_rf = rndforestclassifier.predict(df_general_test[columnas_datos])\n",
    "             \n",
    "plot_importances(rndforestclassifier)\n",
    "\n",
    "prec = precision_score(df_general_test[columnas_target], sepostulo_predicciones_rf)\n",
    "print(\"Precision %.4f\" % (prec * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del rndforestclassifier\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ponderación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_ponderadas = []\n",
    "\n",
    "for i in range (0, len(sepostulo_predicciones_xgb)):\n",
    "    predicciones_ponderadas.append((0.99 * sepostulo_predicciones_xgb[i]) + (0.01 * sepostulo_predicciones_rf[i]))\n",
    "    \n",
    "prec = precision_score(df_general_test[columnas_target], predicciones_ponderadas)\n",
    "#print(\"Precision %.4f\" % (prec * 100))\n",
    "guardar_res(df_resultado, predicciones_ponderadas, \"promedio_ponderado\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_general_entrenamiento\n",
    "del df_general_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test_final = pd.read_csv('../datos_navent_fiuba/test_final_100k.csv')\n",
    "#print(df_test_final.shape)\n",
    "\n",
    "#df_test_final = df_test_final.merge(df_posts_edu, on='idpostulante')\n",
    "#print(df_test_final.shape)\n",
    "#del df_posts_edu\n",
    "#gc.collect()\n",
    "\n",
    "#df_test_final = df_test_final.merge(df_avisos, on='idaviso')\n",
    "#print(df_test_final.shape)\n",
    "#del df_avisos\n",
    "#gc.collect()\n",
    "\n",
    "#df_test_final = df_test_final.merge(df_vistas, on=['idaviso', 'idpostulante'], how='left')\n",
    "#df_test_final['visto'] = df_test_final['visto'].fillna(0)\n",
    "#print(df_test_final.shape)\n",
    "#del df_vistas\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_resultado = pd.DataFrame()\n",
    "#df_resultado['id'] = df_test_final['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "#params = {'n_estimators': 100, 'learning_rate': 0.001 }#, 'max_depth': a, 'min_samples_split': 2, }\n",
    "\n",
    "#xgboostclassifier = GradientBoostingClassifier(**params)\n",
    "#xgboostclassifier.fit(df_general[columnas_datos], df_general[columnas_target].values.ravel())\n",
    "\n",
    "#sepostulo_predicciones_proba = xgboostclassifier.predict_proba(df_test_final[columnas_datos])[:,1]\n",
    "\n",
    "#guardar_res(df_resultado, sepostulo_predicciones_proba, \"XGBoost\", xgboostclassifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
